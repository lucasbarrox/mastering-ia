import os
import numpy as np
from dotenv import load_dotenv
from google import genai
from google.genai import types

load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
client = genai.Client(api_key=api_key)

print("--- ðŸ§  Inicializando Sistema RAG (Neural Search) ---")



# Carregar o texto do arquivo
with open("manual_produto_x.txt", "r") as f:
    texto_completo = f.read()

# Dividir o texto em chunks menores

chunks = [linha.strip() for linha in texto_completo.split('\n') if linha.strip()]

print(f"ðŸ“š Documento carregado. {len(chunks)} fragmentos de informaÃ§Ã£o encontrados.")

# Criar embeddings para cada chunk

print("ðŸ§® Calculando vetores matemÃ¡ticos para cada frase...")

def get_embedding(text):
    # Chama a API do Google para vetorizar o texto
    result = client.models.embed_content(
        model="text-embedding-004",
        contents=text
    )
    return result.embeddings[0].values

# Criamos um "Banco de Dados Vetorial" na memÃ³ria RAM
# database_vetorial = [ (texto_original, vetor_matematico), ... ]
database_vetorial = []
for chunk in chunks:
    vetor = get_embedding(chunk)
    database_vetorial.append({
        "texto": chunk,
        "vetor": np.array(vetor) # Convertendo para NumPy para fazer contas
    })

print("âœ… IndexaÃ§Ã£o concluÃ­da! O sistema aprendeu o documento.")

# FUNÃ‡ÃƒO DE BUSCA DO MELHOR CONTEXTO
def buscar_melhor_contexto(pergunta):
    # A) Vetoriza a pergunta do usuÃ¡rio
    vetor_pergunta = np.array(get_embedding(pergunta))
    
    melhor_score = -1
    melhor_texto = ""
    
    # B) Compara a pergunta com cada pedaÃ§o do documento (Produto Escalar)
    for item in database_vetorial:
        # CÃ¡lculo de Similaridade de Cosseno simplificado (Dot Product)
        score = np.dot(item["vetor"], vetor_pergunta)
        
        if score > melhor_score:
            melhor_score = score
            melhor_texto = item["texto"]
            
    return melhor_texto, melhor_score

# LOOP DE INTERAÃ‡ÃƒO COM O USUÃRIO
print("\n--- ðŸ’¬ Pergunte sobre o X-2000 (Digite 'sair' para fechar) ---")

while True:
    pergunta = input("\nSua dÃºvida: ")
    if pergunta.lower() in ["sair", "exit"]: break
    
    # RETRIEVAL (Buscar o melhor contexto no doc)
    contexto, score = buscar_melhor_contexto(pergunta)
    
    print(f"   ðŸ•µï¸  Fato encontrado no doc (Similaridade: {score:.4f}):")
    print(f"   > '{contexto}'")
    
    if score < 0.65: # Se a similaridade for baixa, talvez o doc nÃ£o tenha a resposta
        print("   âš ï¸  Aviso: NÃ£o tenho certeza se o documento fala sobre isso.")

    # GENERATION (A IA responde usando o contexto)
    prompt_final = f"""
    VocÃª Ã© um assistente tÃ©cnico Ãºtil. Responda Ã  pergunta do usuÃ¡rio usando APENAS o contexto abaixo.
    Se a resposta nÃ£o estiver no contexto, diga "NÃ£o sei informar com base no manual".
    
    CONTEXTO: {contexto}
    
    PERGUNTA: {pergunta}
    """
    
    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=prompt_final
    )
    
    print(f"\nðŸ¤– Resposta da IA: {response.text}")